# Reference List: AI-Led Research Team Governance Framework

## Primary Sources

**ACM Computing Surveys**
- "A Survey on Uncertainty Quantification of Large Language Models: Taxonomy, Open Research Challenges, and Future Directions"
- URL: https://dl.acm.org/doi/10.1145/3744238

**Augment Code**
- "Why Multi-Agent LLM Systems Fail (and How to Fix Them)"
- URL: https://www.augmentcode.com/guides/why-multi-agent-llm-systems-fail-and-how-to-fix-them

**MIT Press - Journal of Design and Science**
- "How To Become A Centaur"
- URL: https://jods.mitpress.mit.edu/pub/issue3-case
- Note: Source of Garry Kasparov's observation on human-AI collaboration in chess

**Nature**
- "Detecting hallucinations in large language models using semantic entropy"
- URL: https://www.nature.com/articles/s41586-024-07421-0
- Note: Documents 0.79 AUROC for hallucination detection using semantic entropy method

**NIST (National Institute of Standards and Technology)**
- "AI Risk Management Framework"
- URL: https://www.nist.gov/itl/ai-risk-management-framework
- PDF: https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf

---

## Methodological Frameworks Referenced

**Cochrane Collaboration**
- Systematic review methodology
- Note: Cited for dual independent execution requirements and quality gate structures

**ISO/IEC 42001**
- AI management system standards
- Note: Referenced for governance structures

**Microsoft Multi-Agent Architectures**
- Note: Referenced for multi-agent system design patterns

**Anthropic Multi-Agent Architectures**
- Note: Referenced for multi-agent system design patterns

---

## Key Research Areas Cited

### Human-AI Collaboration
- Human factors research on automation bias
- Human-in-the-loop systems
- Centaur models of human-AI teamwork