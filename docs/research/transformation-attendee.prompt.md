# Research Prompt: Attendee Experience Data for AI-Enhanced Festivals

**Request ID:** RR-01
**Topic:** Transformation (Q1 - Long-term AI Vision)
**Research Agent:** Claude Sonnet 4.5 or Perplexity Pro
**Estimated Time:** 30-45 minutes
**Output Files:** transformation-attendee.research.md + transformation-attendee.sources.md

---

## Research Questions

### Primary Question
What documented attendee feedback exists regarding AI-enhanced festival experiences (personalized recommendations, dynamic wayfinding, AI-generated content) at festivals deployed 2022-2025?

### Specific Sub-Questions

1. **Survey Data:** What quantitative attendee satisfaction/dissatisfaction rates exist for AI features at festivals?
   - Satisfaction scores (1-5, NPS, etc.)
   - Feature-specific ratings (recommendations vs. wayfinding vs. personalization)
   - Before/after comparisons where AI was introduced mid-festival or year-over-year

2. **Qualitative Feedback:** What do attendees actually say about AI experiences?
   - What feels "helpful" vs. "intrusive"?
   - Quoted feedback from surveys, social media, focus groups
   - Common themes in positive and negative responses

3. **Demographic Differences:** How does AI adoption vary by attendee demographics?
   - Gen Z vs. Millennials vs. Gen X responses
   - Tech-savvy vs. tech-resistant segments
   - First-time vs. returning attendees
   - Domestic vs. international attendees

4. **Mid-Sized Festival Examples:** What AI deployments exist at festivals with 5,000-20,000 attendees?
   - Festival names, locations, attendance figures
   - Specific AI features deployed
   - Documented outcomes or attendee reactions
   - Demonstrates scalability beyond mega-festivals

---

## Context: What We Already Know

**From Initial Research:**
- **Coachella/Spotify integration:** 72% rated AI schedule generation "very helpful" (2023 survey)
- **Bonnaroo iBeacon (2014-2016):** 20% engagement rate; 97,000+ notifications; 12.6 avg per user
- **DICE platform:** 50% of ticket sales via AI recommendations (10M MAU, 2025)
- **teamLab installations:** Positive social media feedback (qualitative, not quantified)

**Gaps:**
- Limited data beyond these 4 examples
- No mid-sized festival case studies (all are major: Coachella 125K+, Bonnaroo 80K+)
- Demographic breakdowns sparse (Coachella survey didn't report age/tech-savvy segments)
- Negative feedback under-documented (need dissenting voices)

---

## Research Strategy

### Recommended Sources

**Primary Targets:**
1. **Festival post-event survey reports** (if publicly available via press releases, industry coverage)
2. **Academic studies** on festival technology adoption (search: "festival mobile app adoption," "music festival technology survey," "AI personalization events")
3. **Industry publications:**
   - Pollstar (concert industry trade publication)
   - IQ Magazine (live entertainment intelligence)
   - Event Manager Blog
   - Skift Meetings (events industry coverage)
4. **Social media analysis:** Twitter/X, Reddit (r/festivals, r/Coachella, etc.), festival-specific forums for organic attendee feedback
5. **Tech vendor case studies:** Festicket, Eventbrite, DICE user research reports

**Search Terms:**
- "festival attendee survey AI" + year (2022, 2023, 2024, 2025)
- "music festival mobile app satisfaction"
- "personalized festival recommendations user feedback"
- "[Festival name] technology survey results"
- "mid-sized music festival AI deployment"

**Geographic Diversity:** Prioritize examples from US, EU, UK, Australia (major festival markets)

---

## Output Specifications

### File 1: transformation-attendee.research.md

**Structure:**
```markdown
# Attendee Experience Research Findings

## Executive Summary
[2-3 paragraphs: key findings, confidence level, integration recommendations]

## Finding 1: Survey Data on AI Feature Satisfaction
[Quantitative data with sources; organize by feature type]

## Finding 2: Qualitative Feedback Themes
[Direct quotes; categorize helpful vs. intrusive]

## Finding 3: Demographic Adoption Patterns
[Age, tech-savvy, first-time vs. returning; data with sources]

## Finding 4: Mid-Sized Festival Case Studies
[Festival names, attendance, AI features, outcomes; minimum 2-3 examples]

## Gaps Remaining
[What couldn't be found despite searching; implications for draft]

## Confidence Assessment
[HIGH/MEDIUM/LOW with justification]

## Integration Recommendations
[Where in Transformation draft this should be added; what claims can now be strengthened]
```

**Word Count:** 800-1,200 words

---

### File 2: transformation-attendee.sources.md

**Structure:**
```markdown
# Sources: Attendee Experience Data

## Tier 1 Sources (Verified - Peer-Reviewed or Official Reports)
[Full citations with URLs/DOIs]

## Tier 2 Sources (Partially Verified - Industry Publications, Press)
[Full citations with URLs]

## Tier 3 Sources (Unverified - Social Media, Anecdotal)
[Full citations with context notes]

## Access Notes
[Any paywalled sources, dead links, or retrieval issues]
```

---

## Quality Control

### Before Submitting Research:

- [ ] All statistics traceable to specific sources (no "studies show" without citation)
- [ ] Confidence level justified based on source quality and quantity
- [ ] Gaps explicitly acknowledged (don't claim to find what doesn't exist)
- [ ] At least 15 sources catalogued
- [ ] At least 2 mid-sized festival examples (if available; flag if not)
- [ ] Demographic data included (if available; note gap if not)
- [ ] Both positive AND negative attendee feedback represented

---

## Escalation Triggers

**Flag for Research Lead if:**
- Research contradicts existing synthesis claims (e.g., Coachella 72% satisfaction is mis-cited)
- No mid-sized festival data exists (may need to revise draft claims about scalability)
- Attendee feedback is overwhelmingly negative for certain AI features (changes tone of draft)

---

**Ready for execution.** Output both .research.md and .sources.md files upon completion.
