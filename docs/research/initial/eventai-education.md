# Critical AI Literacy in Event Management Education: A Research Synthesis

Future event managers need more than technical AI skills—they require the critical capacity to interrogate algorithmic bias, evaluate surveillance ethics, and understand labor displacement in an industry where AI increasingly governs public-facing, high-stakes decisions. This research synthesis establishes the academic foundations for embedding critical AI literacy into university event management curricula, distinguishing it from purely functional training and demonstrating why both dimensions are essential for responsible professional practice.

The UNESCO AI Competency Framework (2024), Harvard's Embedded EthiCS program, and emerging hospitality-specific initiatives at the University of Florida provide verified models for integrating ethical reasoning alongside technical competence. Event managers occupy a unique gatekeeping role—deploying facial recognition at concerts, algorithmic personalization for attendees, and automated labor systems—making critical literacy not optional but foundational to their professional responsibility.

## Defining the two literacies: functional versus critical

**Functional AI literacy** encompasses the skills-based competencies required to effectively operate AI tools in professional contexts. Long and Magerko's foundational 2020 framework defines AI literacy as "a set of competencies that enables individuals to critically evaluate AI technologies; communicate and collaborate effectively with AI; and use AI as a tool online, at home, and in the workplace." The functional dimension addresses questions like *how does AI work?* and *what can AI do?*—encompassing prompt engineering, data input, output interpretation, and tool selection for specific tasks (Long & Magerko, 2020, p. 2).

**Critical AI literacy** addresses a fundamentally different set of competencies: understanding whose interests AI serves, how algorithmic systems embed particular values, and how AI impacts different communities unequally. Velander, Otero, and Milrad (2024) argue that current definitions "often fall short in suggesting how this understanding can help learners critically examine AI, its impact on the socio-technological ecosystem in which it is embedded, and imagine alternatives to current AI practices." The UNESCO AI Competency Framework (2024) operationalizes critical literacy through two of its five competency aspects: "human-centred mindset" and "ethics of AI"—emphasizing that teachers and professionals must "critically assess AI to ensure it enhances learning and promotes inclusivity and equity" (Miao & Cukurova, 2024, p. 7).

Ng et al.'s influential four-dimension framework (2021) maps this distinction onto Bloom's taxonomy: functional literacy corresponds to "Know and Understand AI" and "Use and Apply AI," while critical literacy aligns with "Evaluate and Create AI" and "AI Ethics." The EDUCAUSE AI Literacy Framework (2024) similarly distinguishes "Technical" and "Practical" competencies from "Evaluative" and "Ethical" domains. Critically, Gu and Ericson's 2025 integrative review identified a troubling trend: since generative AI emerged, research has shifted toward post-secondary settings with "a functional literacy perspective," creating "research gaps in promoting critical literacy surrounding AI tools."

## Five reasons critical literacy is essential for event students

Event management presents distinctive conditions that elevate critical AI literacy from elective to essential. The field's public-facing nature, diverse stakeholder networks, and real-time decision environments create amplified risks when AI systems fail or discriminate.

**First, event managers deploy AI systems that encode power relationships requiring ethical scrutiny.** Facial recognition at Taylor Swift's 2018 Rose Bowl concert—scanning approximately 60,000 attendees against a database of stalkers without disclosure or consent—exemplifies how event professionals become arbiters of surveillance ethics. The ACLU documented that "as long as it's private property, they can take your image and do whatever analytics they want with it, including facial recognition," revealing a regulatory gap that demands professional judgment rather than mere compliance (ACLU, 2018). Event managers must understand not just *how* to implement such systems, but *whether* they should, for whom, and under what accountability structures.

**Second, algorithmic bias in event technology reproduces discrimination that functional literacy cannot detect.** Research in hospitality AI demonstrates that "algorithmic personalisation has resulted in poor service experiences for users with less common language or identity characteristics" through digital redlining (Zhou et al., 2022). The ACLU's test of Amazon Rekognition found that **40% of false matches identifying members of Congress as criminal suspects were people of color**, despite representing only 20% of the sample. An event manager skilled in operating facial recognition systems but lacking critical literacy would not know to audit for such disparities or understand their legal and reputational implications.

**Third, labor automation decisions require understanding systemic impacts beyond efficiency metrics.** Tuomi et al. (2020) project that automated systems could replace up to 70% of hospitality tasks, while Barr and Meeks (2025) document that "automation tends to impact jobs that involve routine tasks, which are often held by Black and Latino or Hispanic workers." Event professionals making technology adoption decisions bear responsibility for understanding these distributional consequences—who benefits from AI deployment and who bears its costs.

**Fourth, vendor lock-in and technology dependency create long-term risks that pure operational competence cannot evaluate.** Proprietary data formats, long-term contracts with termination penalties, and skill dependencies limit organizational flexibility. Event managers need critical frameworks to assess data portability, exit strategies, and the power dynamics of platform-dependent operations before signing contracts, not after discovering their attendee data is trapped in systems they cannot migrate.

**Fifth, AI failures at events become immediately visible and socially amplified.** McDonald's AI drive-thru failures went viral on TikTok before the company terminated its IBM partnership in 2024. Air Canada faced legal liability when its chatbot provided incorrect refund information. Event managers cannot "undo" AI decisions made during live events; a wrongful denial of entry based on faulty facial recognition or a discriminatory recommendation algorithm operates in public view with immediate reputational consequences.

## Theoretical foundations from critical pedagogy

Paulo Freire's critique of "banking education"—where students function as passive depositories for teacher-transmitted content—directly challenges AI training that teaches tool operation without critical examination. As Richard Shaull wrote in the foreword to *Pedagogy of the Oppressed*, "our advanced technological society is rapidly making objects of most of us and subtly programming us into conformity to the logic of its system." Freire's alternative, "problem-posing education," positions students as co-creators of knowledge who develop critical consciousness to "perceive social, political, and economic oppression and take action against oppressive elements of society" (Freire, 1970).

Applied to AI education, Freirean pedagogy demands that students not merely learn to use algorithmic systems but interrogate whose interests these systems serve. Farag et al. (2021) extend this analysis in "Freire 2.0: Pedagogy of the Digitally Oppressed," arguing that "the banking of education may refer to digital literacies as well as the education of the digitally oppressed due to an increasing penetration of AI technology and the threats it poses related to discrimination and inequalities."

Jack Mezirow's transformative learning theory (1997) provides complementary grounding, arguing that "critical and autonomous thinking must take precedence over the uncritical assimilation of knowledge." For event management education, this means graduates should not simply accept vendor claims about AI capabilities or efficiency gains but develop capacity for independent evaluation. As Mezirow states, "in contemporary societies we must learn to make our own interpretations rather than act on the purposes, beliefs, judgments, and feelings of others."

The UNESCO Recommendation on the Ethics of Artificial Intelligence (2021), adopted unanimously by 193 member states, establishes international policy expectations: "Public awareness and understanding of AI technologies should be promoted through open and accessible education, civic engagement, AI ethics training etc., so that people can take informed decisions regarding their use of AI systems." This framework positions critical AI literacy not as academic preference but as global educational policy mandate.

## Risks of omitting critical literacy from curricula

Curricula that train event managers only in AI tool operation produce professionals vulnerable to several documented failure modes.

**Unexamined algorithmic bias** represents the most immediate risk. Sailesh (2024) documents in *Events and Tourism Review* that algorithmic decision-making creates "opacity, where users are aware that they were treated unfavourably but have no way to understand that treatment." An event manager who cannot audit recommendation algorithms or attendee profiling systems for discriminatory patterns may unknowingly deploy technology that violates anti-discrimination principles and damages their organization's reputation.

**Uninformed vendor decisions** create structural dependencies that limit organizational flexibility and negotiating leverage. Without critical frameworks for evaluating data ownership, portability, and exit costs, event professionals may commit to technology ecosystems that extract value while providing diminishing returns. The UK Cabinet Office estimated that overreliance on single cloud providers could cost public bodies £894 million—a calculation that requires analytical capacity beyond tool operation.

**Ethical blind spots in surveillance deployment** expose organizations to legal liability and public backlash. The New York State Bar Association's 2024 analysis confirms that "there is little to no regulation in place regarding [facial recognition] use in event venues," meaning professionals must exercise independent ethical judgment in regulatory vacuums. Those trained only in implementation, not evaluation, lack the conceptual resources to make such judgments.

**Reputational harm from AI failures** cannot be managed by professionals who do not understand how systems can fail. The IBM Watson for Oncology collapse—a $4 billion failure due to "erroneous treatment advice" and poor data quality—demonstrates how AI systems confidently produce harmful outputs. Event managers must recognize that AI confidence does not equal accuracy and develop skepticism toward technological solutions that functional literacy alone does not cultivate.

## Curriculum integration models and university examples

The **University of Florida** has implemented the most comprehensive hospitality-specific model through its AI Across the Curriculum Initiative and Graduate Certificate in AI and Data Analytics in Tourism, Hospitality, and Event Management. Developed as part of their SACS-required Quality Enhancement Plan, the program establishes three progression levels—Foundational Awareness, Application, and Creation—across Ng et al.'s framework dimensions. The graduate certificate includes courses explicitly addressing "ethical implications and operational challenges" alongside technical competencies (Southworth et al., 2023).

**Harvard's Embedded EthiCS program** provides a proven model for distributed ethics pedagogy applicable to event management curricula. Philosophy faculty collaborate directly with discipline experts to deliver 50-75 minute ethics modules within existing technical courses—modules on "Algorithmic (Un)fairness," "Ethics of Emotion Recognition," and "Machines and Moral Decision Making." The pedagogical approach uses case studies (such as the SAHELI healthcare AI system), Think-Pair-Share exercises, and 400-word forum posts requiring students to apply welfare, justice, and respect frameworks to AI applications. Harvard has successfully expanded this model to Stanford, University of Toronto, and nine Hispanic-Serving Institutions (Grosz et al., 2019).

The **EthAI Tour Project**, funded by EU Erasmus+, provides vocational-specific case studies directly applicable to event management instruction: Hilton Hotels' AI-powered energy management achieving 20% reductions, Accor Hotels' Winnow Vision food waste system, and Machu Picchu's AI-driven visitor flow regulation. The program teaches privacy-first strategies, transparency requirements, and ethical leadership through industry-grounded scenarios that bridge theoretical frameworks and operational realities.

For assessment, validated instruments include the **SNAIL scale** (Scale for Assessment of Non-Experts' AI Literacy) developed through Delphi study with 53 subject matter experts, and the **AILS** (AI Literacy Scale) using Item Response Theory to measure Long and Magerko's 17 competencies. Rubric-based approaches from the Open University framework assess students' capacity to "consider AI's ethical, societal and environmental impacts" and "consider the agency of AI (control and power dynamics)."

## Practical curriculum integration strategies

Event management programs can integrate critical AI literacy through three complementary approaches.

**Embedded module integration** follows Harvard's distributed pedagogy model: 50-75 minute ethics discussions within existing event technology courses. For example, a session on event registration software could include analysis of algorithmic personalization ethics; instruction on facial recognition deployment could incorporate the Taylor Swift case study with ACLU documentation of bias rates. This approach signals that ethics is integral to professional practice, not a separate concern.

**Case study methodology** draws on documented failures and ethical dilemmas specific to events: the McDonald's chatbot failures and subsequent partnership termination; Air Canada's legal liability for incorrect chatbot advice; Amazon Rekognition's documented bias in law enforcement contexts applicable to venue security. Students analyze cases through frameworks of stakeholder welfare, justice, and respect, then propose alternative approaches.

**Reflective assessment design** requires students to document their AI literacy development through portfolios comparing learner-generated content with AI outputs, reflection logs noting ethical tensions encountered in practical applications, and policy memos proposing governance frameworks for specific event AI deployments. The University of Chicago's Harris School course model combines such assessments with group ideation exercises and interactive problem-solving.

## Conclusion: from optional module to embedded competency

This research synthesis establishes that critical AI literacy is not an optional supplement to event management education but a foundational competency required by the field's public-facing responsibilities, documented AI failure modes, and international policy frameworks. The distinction between functional and critical literacy—established through UNESCO, Long and Magerko, and Ng et al. frameworks—provides clear conceptual architecture for curriculum design. Theoretical grounding from Freire's critical pedagogy and Mezirow's transformative learning theory explains why skill-only training produces professionals unable to exercise the independent ethical judgment that regulatory gaps and novel AI applications demand.

Verified implementation models at the University of Florida, Harvard, and through the EthAI Tour Project demonstrate that integration is practically achievable. Event management educators should adapt Harvard's embedded ethics approach for hospitality contexts, utilize industry-specific case studies from documented AI deployments and failures, and assess critical competencies through reflective instruments rather than operational skill tests alone. The graduates produced—capable of both deploying AI effectively and evaluating its systemic implications—will be better positioned to serve diverse stakeholders, avoid reputational and legal risks, and exercise the professional responsibility that AI-augmented event management increasingly requires.