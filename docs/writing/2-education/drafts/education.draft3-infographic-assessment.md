# Infographic Assessment for education.draft3.md

**Assessment Date:** December 31, 2025
**Context:** Evaluating whether existing infographics (designed for draft2) still support the revised narrative in draft3

---

## Executive Summary

**Status:** ✅ **ALL 4 INFOGRAPHICS STILL WORK**

The narrative restructuring in draft3 maintained all substantive content from draft2—only the *presentation* changed (inventory → prose). Since infographics visualize data and concepts, not prose style, they remain appropriate.

**Critical Note:** All infographics still have the title issue identified in evaluations (designed for standalone, but needed for embedded). Regeneration still required—but visual concepts remain valid.

---

## Infographic #1: Literacy Comparison (Functional vs. Critical)

**Evaluation Reference:** literacy-comparison.eval.md
**Winner:** Variant #1 (92/100 without title)
**Visual Concept:** Side-by-side comparison showing functional literacy (left, tool usage) vs. critical literacy (right, ethical evaluation)

### Narrative Mapping (draft3)

**Supported Section:** Lines 30-71 "Two Types of AI Literacy: Why the Distinction Matters"

**Key Content:**
- **Functional AI Literacy:** Definition, core questions ("How?", "What?"), festival applications (ChatGPT, dashboards, chatbots), Cornell eCornell example
- **Critical AI Literacy:** Core questions ("Whose interests?", "Who benefits?"), UNESCO framework, festival applications (dynamic pricing evaluation, facial recognition assessment, content moderation)
- **The Gap:** "While functional AI literacy teaches *how to use* ChatGPT... critical AI literacy asks *whether AI-generated schedules prioritize sponsor visibility*"

### Assessment: ✅ **PERFECT FIT**

**Why it works:**
- Draft3 maintains clear functional/critical distinction (same as draft2)
- Festival applications examples remain identical
- UNESCO framework dimensions still referenced
- "The Gap" synthesis still present (Line 70 in draft2, embedded in draft3 prose)

**Placement Recommendation:**
- Insert after Line 71 (end of "Two Types of AI Literacy" section)
- Figure caption: "Figure 1: Functional AI literacy focuses on tool usage (left: 'How & What' questions, training examples), while critical AI literacy addresses ethical evaluation (right: 'Why & Who' questions, frameworks for bias and power analysis). The 71% skills gap in hospitality reflects absence of both competencies."

**Regeneration needed?** YES (remove title), but visual concept unchanged

---

## Infographic #2: Academic Integration (3 Lit Universities)

**Evaluation Reference:** academic-integration.eval.md
**Winner:** Variant #4 (94/100 without title)
**Visual Concept:** Three universities lit up (Surrey, Southern Cross, Penn State) against sea of gray, showing "3 out of 100+" programs

### Narrative Mapping (draft3)

**Supported Section:** Lines 74-106 "The Academic Void: Where Three Programs Stand Alone"

**Key Content in draft3:**
- Opening line: "Across 12 major universities in the US, UK, and Australia, only three programs explicitly integrate AI into hospitality curricula"
- **University of Surrey:** "strongest integration found" - MAN2220, MANM432, DIGMY research center
- **Southern Cross University:** "more operational approach" - HOTL3006
- **Penn State:** HM 830 data analytics without explicit AI framing
- Progression narrative: strongest → moderate → minimal
- Event management programs: "gap widens to a void" (Leeds Beckett, UCF Rosen)

### Assessment: ✅ **STILL WORKS PERFECTLY**

**Why it works:**
- Same three universities featured (Surrey, Southern Cross, Penn State)
- Same "3 programs out of hundreds" finding
- Draft3 narrative actually *strengthens* the visual: progression from "strongest" to "minimal" mirrors the visual hierarchy
- The "sea of gray" (other universities) concept aligns with draft3's "zero event management programs" emphasis

**Changes from draft2 → draft3:**
- Narrative *presentation* changed (bulleted list → prose)
- Narrative *content* unchanged (same modules, same assessments, same institutions)
- Visual remains appropriate

**Placement Recommendation:**
- Insert after Line 106 (end of Penn State/event management programs discussion)
- Figure caption: "Figure 2: Only three hospitality programs across major US, UK, and Australian universities explicitly integrate AI into curricula (University of Surrey, Southern Cross University, Penn State), while zero dedicated event management programs offer AI literacy courses. The gap between industry AI adoption (71% report skills shortages) and academic preparation remains stark."

**Regeneration needed?** YES (remove title), but visual concept unchanged

---

## Infographic #3: Skills Gap Cycle (Vicious Cycle)

**Evaluation Reference:** skills-gap-cycle.eval.md
**Winner:** Variant #3 (87/100 without title)
**Visual Concept:** Circular vicious cycle with 4 nodes:
1. Universities: "Can't keep up" → Industry
2. Industry: "Train in-house" → Graduates
3. Graduates: "Lack literacy" → Training
4. Training: "Vendor-led" → Universities (loop closes)

### Narrative Mapping (draft3)

**Supported Section:** Lines 143-156 "Why Universities Lag: Structural Barriers" + Lines 184-197 "The 71% Skills Gap and Who Bears the Cost"

**Key Content in draft3:**
- **71% skills gap, 3% use higher ed** finding (same as draft2)
- **Vicious cycle description:**
  - Line 187-188: "Industry says: 'Universities don't teach relevant AI skills, so we train in-house or hire external consultants.'"
  - Line 188-189: "Universities respond: 'Industry changes so fast we can't keep curricula current, and our faculty lack AI expertise.'"
  - Line 189-191: "The consequence falls on graduates: entry-level festival professionals lack both functional skills... forcing them to learn on the job—often from vendors"
- **Structural barriers:** 12-24 month approvals, 1-2 year faculty hiring, accreditation constraints, research vs. teaching incentives

### Assessment: ✅ **PERFECTLY ALIGNED**

**Why it works:**
- Draft3 explicitly describes the vicious cycle (Lines 187-191)
- Same 71% and 3% statistics
- Narrative flow: structural barriers → vicious cycle → graduate consequences
- "Vendor-led training" critique present (Line 191: "often from vendors with incentives to oversell capabilities and downplay risks")

**Changes from draft2 → draft3:**
- More narrative flow around the cycle concept
- Vicious cycle explicitly named and described (not just implied)
- Same data points, same causation logic

**Placement Recommendation:**
- Insert after Line 197 (end of "The 71% Skills Gap and Who Bears the Cost" section)
- Figure caption: "Figure 3: The vicious cycle reinforcing AI skills gaps in event management education. Universities can't keep curricula current (12-24 month approval timelines), so industry trains in-house. Graduates lack both functional and critical AI literacy, forcing reliance on vendor-led training that oversells capabilities. This perpetuates the gap: only 3% of organizations use higher education for digital training, while 71% report AI/robotics skills shortages."

**Regeneration needed?** YES (remove title), but visual concept unchanged

---

## Infographic #4: Curriculum Structure (4-Module Progression)

**Evaluation Reference:** curriculum-structure.eval.md
**Winner:** Variant #3 (88/100 without title)
**Visual Concept:** 4-module progression (left to right):
- Module 1: Fundamentals (Weeks 1-4) - Blue
- Module 2: Evaluation (Weeks 5-8) - Teal
- Module 3: Ethics (Weeks 9-12) - Purple
- Module 4: Policy (Weeks 13-15) - Coral

### Narrative Mapping (draft3)

**Supported Section:** Lines 165-183 "A semester-long course could address this gap"

**Key Content in draft3:**
- **Weeks 1-4:** AI fundamentals and festival applications (what is AI/ML, festival use cases, hands-on: chatbot deployment and attendance prediction)
- **Weeks 5-8:** Critical evaluation frameworks (reading academic papers/vendor studies, regulatory landscape: GDPR/BIPA/EU AI Act/FTC, case study: Paris 2024 Olympics AI surveillance)
- **Weeks 9-12:** Ethical dilemmas and decision-making (algorithmic bias: NIST study/wrongful arrests/audit methods, power and values: dynamic pricing case study, student project: ethical assessment of AI system)
- **Weeks 13-15:** Industry perspectives and future trends (guest lectures: festival tech directors/privacy advocates/AI vendors, debate: "Should festivals use facial recognition?", final paper: AI deployment policy for fictional festival)

### Assessment: ✅ **EXACT MATCH**

**Why it works:**
- Draft3 maintains identical course structure to draft2
- Same week ranges (1-4, 5-8, 9-12, 13-15)
- Same module themes (Fundamentals → Evaluation → Ethics → Policy)
- Same deliverables mentioned:
  - Chatbot deployment project (Weeks 1-4)
  - Paris 2024 case study (Weeks 5-8)
  - Ethical assessment framework (Weeks 9-12)
  - Facial recognition debate (Week 13-15)
  - AI deployment policy paper (Week 15)

**Changes from draft2 → draft3:**
- Prose flow improved (less bulleted)
- Content *identical*

**Placement Recommendation:**
- Insert after Line 183 (end of proposed course outline)
- Figure caption: "Figure 4: Proposed semester-long AI literacy curriculum for event management programs. The 15-week progression builds from technical fundamentals (Weeks 1-4: what is AI, festival applications) through critical evaluation frameworks (Weeks 5-8: regulatory compliance, vendor assessment) and ethical decision-making (Weeks 9-12: bias auditing, power dynamics) to industry integration (Weeks 13-15: practitioner perspectives, policy development). This structure addresses both functional literacy (tool use) and critical literacy (ethical evaluation) gaps identified across current hospitality programs."

**Regeneration needed?** YES (remove title), but visual concept unchanged

---

## Summary: Infographic-Narrative Alignment

| Infographic | Winner Variant | Draft3 Section | Status | Regeneration Action |
|-------------|----------------|----------------|--------|---------------------|
| Literacy Comparison | #1 (92/100 no title) | Lines 30-71 | ✅ Perfect fit | Remove title, keep visual concept |
| Academic Integration | #4 (94/100 no title) | Lines 74-106 | ✅ Perfect fit | Remove title, keep visual concept |
| Skills Gap Cycle | #3 (87/100 no title) | Lines 143-156, 184-197 | ✅ Perfect fit | Remove title, keep visual concept |
| Curriculum Structure | #3 (88/100 no title) | Lines 165-183 | ✅ Perfect fit | Remove title, keep visual concept |

---

## Regeneration Requirements

**For all 4 infographics:**

1. **Remove titles** (critical context issue from evaluations)
2. **Keep visual designs** (data visualizations remain accurate and appropriate)
3. **Verify data accuracy:**
   - Literacy comparison: Functional vs. Critical distinction ✅
   - Academic integration: Surrey, Southern Cross, Penn State ✅
   - Skills gap cycle: 71%, 3%, vicious cycle nodes ✅
   - Curriculum structure: 4 modules, weeks 1-4/5-8/9-12/13-15 ✅

**No conceptual changes needed** - The narrative restructuring did not alter substantive content, only presentation style. Infographics visualize data/concepts, not prose structure.

---

## Recommendation

**Proceed with infographic regeneration using existing visual concepts** (Variants #1, #4, #3, #3 respectively), removing titles per embedded context requirements identified in evaluations.

**No new infographics needed** - Draft3's narrative improvements enhance *readability* but do not change the *information architecture* that the infographics visualize.

**Estimated effort:** 30-45 minutes per infographic to regenerate without titles (4 infographics × 40 minutes = ~2.5 hours total)

---

**Assessment completed:** December 31, 2025
**Conclusion:** All 4 infographics remain appropriate for draft3. Regenerate to remove titles; visual concepts unchanged.
